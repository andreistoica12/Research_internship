{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all variables in the current environment (if you have already run some cells) - clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from dateutil import parser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the root folder of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_path = '/home/andreistoica12/research-internship'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the folder where we store the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/andreistoica12/research-internship/data/covaxxy-csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 subfolders to store important files and graphs, respectively. If they already existed (from previous runnings of the project), delete the folders and their contents and create empty folders to store the current files and graphs, relevant to the current state of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = os.path.join(rootdir_path, 'files')\n",
    "if os.path.exists(files_path):\n",
    "   shutil.rmtree(files_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(files_path)\n",
    "\n",
    "graphs_path = os.path.join(rootdir_path, 'graphs')\n",
    "if os.path.exists(graphs_path):\n",
    "   shutil.rmtree(graphs_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(graphs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covaxxy_graphs_path = os.path.join(graphs_path, 'covaxxy')\n",
    "if os.path.exists(covaxxy_graphs_path):\n",
    "   shutil.rmtree(covaxxy_graphs_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(covaxxy_graphs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "covaxxy_longitudinal_analysis_graphs = os.path.join(covaxxy_graphs_path, 'longitudinal-analysis')\n",
    "if os.path.exists(covaxxy_longitudinal_analysis_graphs):\n",
    "   shutil.rmtree(covaxxy_longitudinal_analysis_graphs, ignore_errors=False, onerror=None)\n",
    "os.makedirs(covaxxy_longitudinal_analysis_graphs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of the current data files need for my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet_ids--2021-03-02.csv',\n",
       " 'tweet_ids--2021-03-03.csv',\n",
       " 'tweet_ids--2021-03-05.csv',\n",
       " 'tweet_ids--2021-03-04.csv',\n",
       " 'tweet_ids--2021-03-01.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity's and consistency's sake, I will store all data in chronological order, so we sort the list of file names from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list.sort(key=lambda date: datetime.strptime(date, \"tweet_ids--%Y-%m-%d.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet_ids--2021-03-01.csv',\n",
       " 'tweet_ids--2021-03-02.csv',\n",
       " 'tweet_ids--2021-03-03.csv',\n",
       " 'tweet_ids--2021-03-04.csv',\n",
       " 'tweet_ids--2021-03-05.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I parse the date of the tweets from the file names and transform them into datetime objects. This makes it easier to get the day/month/year, as they are already properties of such type of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_datetime = [ datetime.strptime(key, \"tweet_ids--%Y-%m-%d.csv\") for key in file_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2021, 3, 1, 0, 0),\n",
       " datetime.datetime(2021, 3, 2, 0, 0),\n",
       " datetime.datetime(2021, 3, 3, 0, 0),\n",
       " datetime.datetime(2021, 3, 4, 0, 0),\n",
       " datetime.datetime(2021, 3, 5, 0, 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, I will store each .csv file as a pandas DataFrame in a dictionary, where the keys represent a simplified form of the date. So, here, I will format the dates from the datetime objects into simple strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [ \"{day}-{month}-{year}\".format(day=key.day, month=key.month, year=key.year) for key in keys_datetime ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-3-2021', '2-3-2021', '3-3-2021', '4-3-2021', '5-3-2021']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read the data from the files, I need the paths of the files to be passed on to the read_csv() function. The order of the days in the file paths needs to be consistent with the order of the dates in the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [ os.path.join(data_path, file) for file in file_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/andreistoica12/research-internship/data/covaxxy-csv/tweet_ids--2021-03-01.csv',\n",
       " '/home/andreistoica12/research-internship/data/covaxxy-csv/tweet_ids--2021-03-02.csv',\n",
       " '/home/andreistoica12/research-internship/data/covaxxy-csv/tweet_ids--2021-03-03.csv',\n",
       " '/home/andreistoica12/research-internship/data/covaxxy-csv/tweet_ids--2021-03-04.csv',\n",
       " '/home/andreistoica12/research-internship/data/covaxxy-csv/tweet_ids--2021-03-05.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will build the dictionary where the keys represent the formatted simple date and the values are dataframes corresponding to each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = dict()\n",
    "for i in range(len(file_list)):\n",
    "    days[keys[i]] = pd.read_csv(paths[i], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-01T00:01:56.000Z</td>\n",
       "      <td>1366176845561962503</td>\n",
       "      <td>14914686</td>\n",
       "      <td>@UK_Centrist @_PhB @RolandBakerIII @RicardLope...</td>\n",
       "      <td>639</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>1366176846895738883</td>\n",
       "      <td>2402490445</td>\n",
       "      <td>RT @THE_Russell: Berijiklian: \"There may be a ...</td>\n",
       "      <td>1215</td>\n",
       "      <td>4924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>1366176847822811145</td>\n",
       "      <td>56147198</td>\n",
       "      <td>RT @YvetteCooperMP: Cases of the Brazil varian...</td>\n",
       "      <td>1304</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>1366176848225464323</td>\n",
       "      <td>1252300308165857280</td>\n",
       "      <td>RT @OfficialKat: Cannot wait for the vaccine. ...</td>\n",
       "      <td>154</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>1366176848284057600</td>\n",
       "      <td>190474968</td>\n",
       "      <td>New vaccination appointments available tomorro...</td>\n",
       "      <td>1410</td>\n",
       "      <td>1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606463</th>\n",
       "      <td>2021-03-01T03:27:26.000Z</td>\n",
       "      <td>1366228560290009091</td>\n",
       "      <td>1199985222432878592</td>\n",
       "      <td>@goppiaziz At least, vaccinated person can get...</td>\n",
       "      <td>66</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606464</th>\n",
       "      <td>2021-03-01T03:27:26.000Z</td>\n",
       "      <td>1366228561250701317</td>\n",
       "      <td>172453839</td>\n",
       "      <td>RT @POTUS: The more people that get vaccinated...</td>\n",
       "      <td>798</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606465</th>\n",
       "      <td>2021-03-01T03:27:26.000Z</td>\n",
       "      <td>1366228561389051905</td>\n",
       "      <td>47777004</td>\n",
       "      <td>RT @OfficialKat: Cannot wait for the vaccine. ...</td>\n",
       "      <td>2269</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606466</th>\n",
       "      <td>2021-03-01T03:27:27.000Z</td>\n",
       "      <td>1366228561724645376</td>\n",
       "      <td>1422286680</td>\n",
       "      <td>@Haugmoen It seems to be easier now that I hav...</td>\n",
       "      <td>290</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606467</th>\n",
       "      <td>2021-03-01T03:27:27.000Z</td>\n",
       "      <td>1366228562223656969</td>\n",
       "      <td>1284431376544980992</td>\n",
       "      <td>RT @AdityaRajKaul: Prime Minister of India @na...</td>\n",
       "      <td>3505</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606468 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at             tweet_id            author_id  \\\n",
       "0       2021-03-01T00:01:56.000Z  1366176845561962503             14914686   \n",
       "1       2021-03-01T00:01:57.000Z  1366176846895738883           2402490445   \n",
       "2       2021-03-01T00:01:57.000Z  1366176847822811145             56147198   \n",
       "3       2021-03-01T00:01:57.000Z  1366176848225464323  1252300308165857280   \n",
       "4       2021-03-01T00:01:57.000Z  1366176848284057600            190474968   \n",
       "...                          ...                  ...                  ...   \n",
       "606463  2021-03-01T03:27:26.000Z  1366228560290009091  1199985222432878592   \n",
       "606464  2021-03-01T03:27:26.000Z  1366228561250701317            172453839   \n",
       "606465  2021-03-01T03:27:26.000Z  1366228561389051905             47777004   \n",
       "606466  2021-03-01T03:27:27.000Z  1366228561724645376           1422286680   \n",
       "606467  2021-03-01T03:27:27.000Z  1366228562223656969  1284431376544980992   \n",
       "\n",
       "                                                     text  followers_count  \\\n",
       "0       @UK_Centrist @_PhB @RolandBakerIII @RicardLope...              639   \n",
       "1       RT @THE_Russell: Berijiklian: \"There may be a ...             1215   \n",
       "2       RT @YvetteCooperMP: Cases of the Brazil varian...             1304   \n",
       "3       RT @OfficialKat: Cannot wait for the vaccine. ...              154   \n",
       "4       New vaccination appointments available tomorro...             1410   \n",
       "...                                                   ...              ...   \n",
       "606463  @goppiaziz At least, vaccinated person can get...               66   \n",
       "606464  RT @POTUS: The more people that get vaccinated...              798   \n",
       "606465  RT @OfficialKat: Cannot wait for the vaccine. ...             2269   \n",
       "606466  @Haugmoen It seems to be easier now that I hav...              290   \n",
       "606467  RT @AdityaRajKaul: Prime Minister of India @na...             3505   \n",
       "\n",
       "        following_count  \n",
       "0                   349  \n",
       "1                  4924  \n",
       "2                   589  \n",
       "3                   267  \n",
       "4                  1602  \n",
       "...                 ...  \n",
       "606463              119  \n",
       "606464             4999  \n",
       "606465             1650  \n",
       "606466              293  \n",
       "606467              206  \n",
       "\n",
       "[606468 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days['1-3-2021']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the distribution of the tweets per hour, I will parse the \"created_at\" column, extract the hour property and create a separate column in each dataframe. I will place it next to the \"created_at\" column in order to be easily verifiable. Data originates frmo the Twitter API, so it comes in a standard ISO 8601 format, which can be easily parsed using the parser module from the dateutil package.\n",
    "\n",
    "Note: the cell below runs for approximately 2m30' on my machine (~25-30 seconds for each file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, day in days.items():\n",
    "    if 'hour' not in day.columns:\n",
    "        hours = []\n",
    "        for time in day.loc[:,\"created_at\"]:\n",
    "            hour = parser.parse(time).hour\n",
    "            hours.append(hour)\n",
    "        day.insert(1, \"hour\", hours, True)\n",
    "        print(key + \" - added 'hour' column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>hour</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-01T00:01:56.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1366176845561962503</td>\n",
       "      <td>14914686</td>\n",
       "      <td>@UK_Centrist @_PhB @RolandBakerIII @RicardLope...</td>\n",
       "      <td>639</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1366176846895738883</td>\n",
       "      <td>2402490445</td>\n",
       "      <td>RT @THE_Russell: Berijiklian: \"There may be a ...</td>\n",
       "      <td>1215</td>\n",
       "      <td>4924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1366176847822811145</td>\n",
       "      <td>56147198</td>\n",
       "      <td>RT @YvetteCooperMP: Cases of the Brazil varian...</td>\n",
       "      <td>1304</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1366176848225464323</td>\n",
       "      <td>1252300308165857280</td>\n",
       "      <td>RT @OfficialKat: Cannot wait for the vaccine. ...</td>\n",
       "      <td>154</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-01T00:01:57.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1366176848284057600</td>\n",
       "      <td>190474968</td>\n",
       "      <td>New vaccination appointments available tomorro...</td>\n",
       "      <td>1410</td>\n",
       "      <td>1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606463</th>\n",
       "      <td>2021-03-01T03:27:26.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>1366228560290009091</td>\n",
       "      <td>1199985222432878592</td>\n",
       "      <td>@goppiaziz At least, vaccinated person can get...</td>\n",
       "      <td>66</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606464</th>\n",
       "      <td>2021-03-01T03:27:26.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>1366228561250701317</td>\n",
       "      <td>172453839</td>\n",
       "      <td>RT @POTUS: The more people that get vaccinated...</td>\n",
       "      <td>798</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606465</th>\n",
       "      <td>2021-03-01T03:27:26.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>1366228561389051905</td>\n",
       "      <td>47777004</td>\n",
       "      <td>RT @OfficialKat: Cannot wait for the vaccine. ...</td>\n",
       "      <td>2269</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606466</th>\n",
       "      <td>2021-03-01T03:27:27.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>1366228561724645376</td>\n",
       "      <td>1422286680</td>\n",
       "      <td>@Haugmoen It seems to be easier now that I hav...</td>\n",
       "      <td>290</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606467</th>\n",
       "      <td>2021-03-01T03:27:27.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>1366228562223656969</td>\n",
       "      <td>1284431376544980992</td>\n",
       "      <td>RT @AdityaRajKaul: Prime Minister of India @na...</td>\n",
       "      <td>3505</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606468 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at  hour             tweet_id  \\\n",
       "0       2021-03-01T00:01:56.000Z     0  1366176845561962503   \n",
       "1       2021-03-01T00:01:57.000Z     0  1366176846895738883   \n",
       "2       2021-03-01T00:01:57.000Z     0  1366176847822811145   \n",
       "3       2021-03-01T00:01:57.000Z     0  1366176848225464323   \n",
       "4       2021-03-01T00:01:57.000Z     0  1366176848284057600   \n",
       "...                          ...   ...                  ...   \n",
       "606463  2021-03-01T03:27:26.000Z     3  1366228560290009091   \n",
       "606464  2021-03-01T03:27:26.000Z     3  1366228561250701317   \n",
       "606465  2021-03-01T03:27:26.000Z     3  1366228561389051905   \n",
       "606466  2021-03-01T03:27:27.000Z     3  1366228561724645376   \n",
       "606467  2021-03-01T03:27:27.000Z     3  1366228562223656969   \n",
       "\n",
       "                  author_id  \\\n",
       "0                  14914686   \n",
       "1                2402490445   \n",
       "2                  56147198   \n",
       "3       1252300308165857280   \n",
       "4                 190474968   \n",
       "...                     ...   \n",
       "606463  1199985222432878592   \n",
       "606464            172453839   \n",
       "606465             47777004   \n",
       "606466           1422286680   \n",
       "606467  1284431376544980992   \n",
       "\n",
       "                                                     text  followers_count  \\\n",
       "0       @UK_Centrist @_PhB @RolandBakerIII @RicardLope...              639   \n",
       "1       RT @THE_Russell: Berijiklian: \"There may be a ...             1215   \n",
       "2       RT @YvetteCooperMP: Cases of the Brazil varian...             1304   \n",
       "3       RT @OfficialKat: Cannot wait for the vaccine. ...              154   \n",
       "4       New vaccination appointments available tomorro...             1410   \n",
       "...                                                   ...              ...   \n",
       "606463  @goppiaziz At least, vaccinated person can get...               66   \n",
       "606464  RT @POTUS: The more people that get vaccinated...              798   \n",
       "606465  RT @OfficialKat: Cannot wait for the vaccine. ...             2269   \n",
       "606466  @Haugmoen It seems to be easier now that I hav...              290   \n",
       "606467  RT @AdityaRajKaul: Prime Minister of India @na...             3505   \n",
       "\n",
       "        following_count  \n",
       "0                   349  \n",
       "1                  4924  \n",
       "2                   589  \n",
       "3                   267  \n",
       "4                  1602  \n",
       "...                 ...  \n",
       "606463              119  \n",
       "606464             4999  \n",
       "606465             1650  \n",
       "606466              293  \n",
       "606467              206  \n",
       "\n",
       "[606468 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days['1-3-2021']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final distribution is made up of the sum of all individual days' distributions. I save a figure in the graphs/ folder for each day, as well as an overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_distribution = pd.Series(0, index=days['1-3-2021'].loc[:,'hour'].sort_values(ascending=True).unique())\n",
    "for key, day in days.items():\n",
    "    hour_column_ascending = day.loc[:,\"hour\"].sort_values(ascending=True)\n",
    "    distribution = hour_column_ascending.value_counts()[hour_column_ascending.unique()]\n",
    "    final_distribution = final_distribution.add(distribution)\n",
    "    axes = distribution.plot(kind='bar')\n",
    "    figure_path = f\"{covaxxy_longitudinal_analysis_graphs}/{key}_distribution.png\"\n",
    "    axes.figure.savefig(figure_path)\n",
    "    plt.close()\n",
    "axes = final_distribution.plot(kind='bar')\n",
    "figure_path = f\"{covaxxy_longitudinal_analysis_graphs}/overall_distribution.png\"\n",
    "axes.figure.savefig(figure_path)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "243101c165aceacaf115b49fc146265224cf91574f24df3021157e0d2dabdb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
