{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all variables in the current environment (if you have already run some cells) - clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from IPython.core.getipython import get_ipython\n",
    "from matplotlib import pyplot as plt\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_path = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the folder where the raw dataset (the initial .csv files) is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_possibilities = ['15_days', '25_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_days = dataset_possibilities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(rootdir_path, 'data', f'covaxxy_merged_{number_of_days}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = os.path.join(rootdir_path, 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_unique_dates = os.path.join(files_path, f'unique_dates_{number_of_days}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_changes_path = os.path.join(files_path, f'opinion-changes-{number_of_days}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_path = os.path.join(rootdir_path, 'graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "covaxxy_graphs_path = os.path.join(graphs_path, 'covaxxy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create subfolders specific to the different types of analyses performed in the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1 subfolder within the graphs/covaxxy/ folder to store graphs referring to differences in opinion changes for the covaxxy dataset. If it already existed (from previous runnings of the project), delete the folder and its contents and create an empty folder to store the current graphs, relevant to the current state of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "covaxxy_deltas_OC_graphs_path = os.path.join(covaxxy_graphs_path, f'deltas-OC-{number_of_days}')\n",
    "if os.path.exists(covaxxy_deltas_OC_graphs_path):\n",
    "   shutil.rmtree(covaxxy_deltas_OC_graphs_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(covaxxy_deltas_OC_graphs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covaxxy_longitudinal_analysis_graphs_path = os.path.join(covaxxy_graphs_path, 'longitudinal-analysis')\n",
    "# if os.path.exists(covaxxy_longitudinal_analysis_graphs_path):\n",
    "#    shutil.rmtree(covaxxy_longitudinal_analysis_graphs_path, ignore_errors=False, onerror=None)\n",
    "# os.makedirs(covaxxy_longitudinal_analysis_graphs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_days = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_int(reference_id):\n",
    "    try:\n",
    "        return int(reference_id)\n",
    "    except ValueError:\n",
    "        return reference_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_days['reference_id'] = merged_days['reference_id'].apply(string_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>credible</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>urls</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_author_id</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>retweeted_screen_name</th>\n",
       "      <th>user_mentions_id</th>\n",
       "      <th>user_mentions_screen_name</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_tweet_id</th>\n",
       "      <th>in_reply_to_username</th>\n",
       "      <th>reference_type</th>\n",
       "      <th>reference_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-24 18:00:10+00:00</td>\n",
       "      <td>1364636249852502018</td>\n",
       "      <td>1</td>\n",
       "      <td>107501328</td>\n",
       "      <td>RT @Maricopahealth: At one of our community po...</td>\n",
       "      <td>#</td>\n",
       "      <td>2-1-1 Arizona</td>\n",
       "      <td>211arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>...</td>\n",
       "      <td>29816986</td>\n",
       "      <td>1364632754042802176</td>\n",
       "      <td>Maricopahealth</td>\n",
       "      <td>29816986</td>\n",
       "      <td>Maricopahealth</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1364632754042802176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-24 18:00:18+00:00</td>\n",
       "      <td>1364636282664574978</td>\n",
       "      <td>1</td>\n",
       "      <td>26761523</td>\n",
       "      <td>Ready for DAY 2 of State of the Valley? Join u...</td>\n",
       "      <td>jointventure.org,twitter.com,</td>\n",
       "      <td>Joint Venture SV</td>\n",
       "      <td>JointVentureSVN</td>\n",
       "      <td>False</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-24 18:00:30+00:00</td>\n",
       "      <td>1364636333596008449</td>\n",
       "      <td>1</td>\n",
       "      <td>1234926105234034689</td>\n",
       "      <td>RT @SteveStaeger: When #COVID19Colorado is ove...</td>\n",
       "      <td>#</td>\n",
       "      <td>Colorado Coronavirus Updates</td>\n",
       "      <td>COVIDinColorado</td>\n",
       "      <td>False</td>\n",
       "      <td>Denver, Colorado</td>\n",
       "      <td>...</td>\n",
       "      <td>182037688</td>\n",
       "      <td>1364293582157307906</td>\n",
       "      <td>SteveStaeger</td>\n",
       "      <td>182037688</td>\n",
       "      <td>SteveStaeger</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1364293582157307906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-24 18:03:16+00:00</td>\n",
       "      <td>1364637028948709377</td>\n",
       "      <td>1</td>\n",
       "      <td>1329106574082641920</td>\n",
       "      <td>#SD37: Starting next week, @OCHealth will star...</td>\n",
       "      <td>bit.ly,www.ocregister.com,</td>\n",
       "      <td>Senator Dave Min</td>\n",
       "      <td>SenDaveMin</td>\n",
       "      <td>True</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>36069538</td>\n",
       "      <td>ochealth</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-24 18:03:35+00:00</td>\n",
       "      <td>1364637110951583746</td>\n",
       "      <td>1</td>\n",
       "      <td>1363750425459970048</td>\n",
       "      <td>RT @jatinde45666597: Vaccination has been star...</td>\n",
       "      <td>#</td>\n",
       "      <td>Reena Sharma</td>\n",
       "      <td>write2reena</td>\n",
       "      <td>False</td>\n",
       "      <td>Auckland, New Zealand</td>\n",
       "      <td>...</td>\n",
       "      <td>1295748297529884673</td>\n",
       "      <td>1364087633538859008</td>\n",
       "      <td>jatinde45666597</td>\n",
       "      <td>1295748297529884673</td>\n",
       "      <td>jatinde45666597</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1364087633538859008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10723864</th>\n",
       "      <td>2021-03-20 23:59:42+00:00</td>\n",
       "      <td>1373424038111023106</td>\n",
       "      <td>1</td>\n",
       "      <td>827349983577796608</td>\n",
       "      <td>RT @altNOAA: PSA: If you're in #Oklahoma and a...</td>\n",
       "      <td>#</td>\n",
       "      <td>Howard Hudson</td>\n",
       "      <td>hwrdhdsn</td>\n",
       "      <td>False</td>\n",
       "      <td>Medford, OR</td>\n",
       "      <td>...</td>\n",
       "      <td>824126001936474113</td>\n",
       "      <td>1373418517484220418</td>\n",
       "      <td>altNOAA</td>\n",
       "      <td>824126001936474113</td>\n",
       "      <td>altNOAA</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1373418517484220418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10723865</th>\n",
       "      <td>2021-03-20 23:59:42+00:00</td>\n",
       "      <td>1373424038895321101</td>\n",
       "      <td>1</td>\n",
       "      <td>828337737388285952</td>\n",
       "      <td>RT @maura_resister: Covid rates are trending i...</td>\n",
       "      <td>#</td>\n",
       "      <td>KY R.N. Votes Blue😷🦋🌊</td>\n",
       "      <td>changemustcome7</td>\n",
       "      <td>False</td>\n",
       "      <td>Blue dot in red state</td>\n",
       "      <td>...</td>\n",
       "      <td>1167775229109837825</td>\n",
       "      <td>1373420544830361602</td>\n",
       "      <td>maura_resister</td>\n",
       "      <td>1167775229109837825</td>\n",
       "      <td>maura_resister</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1373420544830361602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10723866</th>\n",
       "      <td>2021-03-20 23:59:43+00:00</td>\n",
       "      <td>1373424044100440072</td>\n",
       "      <td>1</td>\n",
       "      <td>126514742</td>\n",
       "      <td>RT @Best_of_PT: The tiny island of #Corvo in t...</td>\n",
       "      <td>#</td>\n",
       "      <td>Javier RG</td>\n",
       "      <td>Rxavier23</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>894905209159331840</td>\n",
       "      <td>1373313858476068869</td>\n",
       "      <td>Best_of_PT</td>\n",
       "      <td>894905209159331840</td>\n",
       "      <td>Best_of_PT</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1373313858476068869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10723867</th>\n",
       "      <td>2021-03-20 23:59:43+00:00</td>\n",
       "      <td>1373424044318420993</td>\n",
       "      <td>1</td>\n",
       "      <td>2918822815</td>\n",
       "      <td>@sethsliltweeter @EncoreBeachClub That’s a goo...</td>\n",
       "      <td>#</td>\n",
       "      <td>Jason Titus</td>\n",
       "      <td>eezeemonee</td>\n",
       "      <td>False</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>1289682623757918209</td>\n",
       "      <td>sethsliltweeter</td>\n",
       "      <td>1289682623757918209</td>\n",
       "      <td>1373417100472033283</td>\n",
       "      <td>sethsliltweeter</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1373417100472033283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10723868</th>\n",
       "      <td>2021-03-20 23:59:43+00:00</td>\n",
       "      <td>1373424044498956288</td>\n",
       "      <td>1</td>\n",
       "      <td>1340748784121360388</td>\n",
       "      <td>RT @youth_unheard: Such a great atmosphere tod...</td>\n",
       "      <td>#</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Sara31885520</td>\n",
       "      <td>False</td>\n",
       "      <td>#</td>\n",
       "      <td>...</td>\n",
       "      <td>1308059523458961409</td>\n",
       "      <td>1373381756188028932</td>\n",
       "      <td>youth_unheard</td>\n",
       "      <td>1308059523458961409</td>\n",
       "      <td>youth_unheard</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1373381756188028932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10723869 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         created_at             tweet_id  credible  \\\n",
       "0         2021-02-24 18:00:10+00:00  1364636249852502018         1   \n",
       "1         2021-02-24 18:00:18+00:00  1364636282664574978         1   \n",
       "2         2021-02-24 18:00:30+00:00  1364636333596008449         1   \n",
       "3         2021-02-24 18:03:16+00:00  1364637028948709377         1   \n",
       "4         2021-02-24 18:03:35+00:00  1364637110951583746         1   \n",
       "...                             ...                  ...       ...   \n",
       "10723864  2021-03-20 23:59:42+00:00  1373424038111023106         1   \n",
       "10723865  2021-03-20 23:59:42+00:00  1373424038895321101         1   \n",
       "10723866  2021-03-20 23:59:43+00:00  1373424044100440072         1   \n",
       "10723867  2021-03-20 23:59:43+00:00  1373424044318420993         1   \n",
       "10723868  2021-03-20 23:59:43+00:00  1373424044498956288         1   \n",
       "\n",
       "                    author_id  \\\n",
       "0                   107501328   \n",
       "1                    26761523   \n",
       "2         1234926105234034689   \n",
       "3         1329106574082641920   \n",
       "4         1363750425459970048   \n",
       "...                       ...   \n",
       "10723864   827349983577796608   \n",
       "10723865   828337737388285952   \n",
       "10723866            126514742   \n",
       "10723867           2918822815   \n",
       "10723868  1340748784121360388   \n",
       "\n",
       "                                                       text  \\\n",
       "0         RT @Maricopahealth: At one of our community po...   \n",
       "1         Ready for DAY 2 of State of the Valley? Join u...   \n",
       "2         RT @SteveStaeger: When #COVID19Colorado is ove...   \n",
       "3         #SD37: Starting next week, @OCHealth will star...   \n",
       "4         RT @jatinde45666597: Vaccination has been star...   \n",
       "...                                                     ...   \n",
       "10723864  RT @altNOAA: PSA: If you're in #Oklahoma and a...   \n",
       "10723865  RT @maura_resister: Covid rates are trending i...   \n",
       "10723866  RT @Best_of_PT: The tiny island of #Corvo in t...   \n",
       "10723867  @sethsliltweeter @EncoreBeachClub That’s a goo...   \n",
       "10723868  RT @youth_unheard: Such a great atmosphere tod...   \n",
       "\n",
       "                                   urls                          name  \\\n",
       "0                                     #                 2-1-1 Arizona   \n",
       "1         jointventure.org,twitter.com,              Joint Venture SV   \n",
       "2                                     #  Colorado Coronavirus Updates   \n",
       "3            bit.ly,www.ocregister.com,              Senator Dave Min   \n",
       "4                                     #                  Reena Sharma   \n",
       "...                                 ...                           ...   \n",
       "10723864                              #                 Howard Hudson   \n",
       "10723865                              #         KY R.N. Votes Blue😷🦋🌊   \n",
       "10723866                              #                     Javier RG   \n",
       "10723867                              #                   Jason Titus   \n",
       "10723868                              #                          Sara   \n",
       "\n",
       "                 username  verified               location  ...  \\\n",
       "0              211arizona     False                Arizona  ...   \n",
       "1         JointVentureSVN     False           San Jose, CA  ...   \n",
       "2         COVIDinColorado     False       Denver, Colorado  ...   \n",
       "3              SenDaveMin      True             Irvine, CA  ...   \n",
       "4             write2reena     False  Auckland, New Zealand  ...   \n",
       "...                   ...       ...                    ...  ...   \n",
       "10723864         hwrdhdsn     False            Medford, OR  ...   \n",
       "10723865  changemustcome7     False  Blue dot in red state  ...   \n",
       "10723866        Rxavier23     False                      #  ...   \n",
       "10723867       eezeemonee     False           San Jose, CA  ...   \n",
       "10723868     Sara31885520     False                      #  ...   \n",
       "\n",
       "            retweet_author_id           retweet_id  retweeted_screen_name  \\\n",
       "0                    29816986  1364632754042802176         Maricopahealth   \n",
       "1                           #                    #                      #   \n",
       "2                   182037688  1364293582157307906           SteveStaeger   \n",
       "3                           #                    #                      #   \n",
       "4         1295748297529884673  1364087633538859008        jatinde45666597   \n",
       "...                       ...                  ...                    ...   \n",
       "10723864   824126001936474113  1373418517484220418                altNOAA   \n",
       "10723865  1167775229109837825  1373420544830361602         maura_resister   \n",
       "10723866   894905209159331840  1373313858476068869             Best_of_PT   \n",
       "10723867                    #                    #                      #   \n",
       "10723868  1308059523458961409  1373381756188028932          youth_unheard   \n",
       "\n",
       "             user_mentions_id  user_mentions_screen_name  in_reply_to_user_id  \\\n",
       "0                    29816986             Maricopahealth                    #   \n",
       "1                           #                          #                    #   \n",
       "2                   182037688               SteveStaeger                    #   \n",
       "3                    36069538                   ochealth                    #   \n",
       "4         1295748297529884673            jatinde45666597                    #   \n",
       "...                       ...                        ...                  ...   \n",
       "10723864   824126001936474113                    altNOAA                    #   \n",
       "10723865  1167775229109837825             maura_resister                    #   \n",
       "10723866   894905209159331840                 Best_of_PT                    #   \n",
       "10723867  1289682623757918209            sethsliltweeter  1289682623757918209   \n",
       "10723868  1308059523458961409              youth_unheard                    #   \n",
       "\n",
       "          in_reply_to_tweet_id in_reply_to_username reference_type  \\\n",
       "0                            #                    #      retweeted   \n",
       "1                            #                    #              #   \n",
       "2                            #                    #      retweeted   \n",
       "3                            #                    #              #   \n",
       "4                            #                    #      retweeted   \n",
       "...                        ...                  ...            ...   \n",
       "10723864                     #                    #      retweeted   \n",
       "10723865                     #                    #      retweeted   \n",
       "10723866                     #                    #      retweeted   \n",
       "10723867   1373417100472033283      sethsliltweeter     replied_to   \n",
       "10723868                     #                    #      retweeted   \n",
       "\n",
       "                 reference_id  \n",
       "0         1364632754042802176  \n",
       "1                           #  \n",
       "2         1364293582157307906  \n",
       "3                           #  \n",
       "4         1364087633538859008  \n",
       "...                       ...  \n",
       "10723864  1373418517484220418  \n",
       "10723865  1373420544830361602  \n",
       "10723866  1373313858476068869  \n",
       "10723867  1373417100472033283  \n",
       "10723868  1373381756188028932  \n",
       "\n",
       "[10723869 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'tweet_id', 'credible', 'author_id', 'text', 'urls',\n",
       "       'name', 'username', 'verified', 'location', 'followers_count',\n",
       "       'following_count', 'tweet_count', 'like_count', 'quote_count',\n",
       "       'reply_count', 'retweet_count', 'retweet_author_id', 'retweet_id',\n",
       "       'retweeted_screen_name', 'user_mentions_id',\n",
       "       'user_mentions_screen_name', 'in_reply_to_user_id',\n",
       "       'in_reply_to_tweet_id', 'in_reply_to_username', 'reference_type',\n",
       "       'reference_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_days.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the column names\n",
    "col_names = merged_days.columns.to_list()\n",
    "\n",
    "# save the list to a file\n",
    "with open(os.path.join(files_path, 'columns.txt'), 'w') as f:\n",
    "    for col_name in col_names:\n",
    "        f.write(col_name + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXACT DAYS IN OUR DATASET:\n",
    "\n",
    "Note: I double checked which days were actually used in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-02-2021 - 334 tweets\n",
      "25-02-2021 - 933 tweets\n",
      "26-02-2021 - 1110 tweets\n",
      "27-02-2021 - 871 tweets\n",
      "28-02-2021 - 792 tweets\n",
      "01-03-2021 - 608540 tweets\n",
      "02-03-2021 - 691842 tweets\n",
      "03-03-2021 - 667152 tweets\n",
      "04-03-2021 - 516891 tweets\n",
      "05-03-2021 - 504369 tweets\n",
      "06-03-2021 - 401596 tweets\n",
      "07-03-2021 - 362643 tweets\n",
      "08-03-2021 - 359209 tweets\n",
      "09-03-2021 - 466151 tweets\n",
      "10-03-2021 - 541263 tweets\n",
      "11-03-2021 - 667231 tweets\n",
      "12-03-2021 - 745042 tweets\n",
      "13-03-2021 - 431356 tweets\n",
      "14-03-2021 - 442648 tweets\n",
      "15-03-2021 - 586684 tweets\n",
      "16-03-2021 - 674996 tweets\n",
      "17-03-2021 - 536724 tweets\n",
      "18-03-2021 - 581944 tweets\n",
      "19-03-2021 - 501221 tweets\n",
      "20-03-2021 - 432327 tweets\n"
     ]
    }
   ],
   "source": [
    "exact_days_info = []\n",
    "\n",
    "with open(path_to_unique_dates, 'r') as f:\n",
    "    for line in f:\n",
    "        exact_days_info.append(line.strip())\n",
    "\n",
    "for day_info in exact_days_info:\n",
    "    print(day_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REACTIONS\n",
    "\n",
    "There are 3 types of reactions:\n",
    "- replies ('replied_to')\n",
    "- quotes ('quoted')\n",
    "- retweets ('retweeted')\n",
    "\n",
    "All possible combinations of reactions types you may wish to take into account further down the line are specified in the full list below. \n",
    "\n",
    "The reaction_types list should be equal to one of the elements of the full list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_types_full_list = [['quoted'], \n",
    "                            ['quoted', 'retweeted'], \n",
    "                            ['replied_to'], \n",
    "                            ['replied_to', 'quoted'], \n",
    "                            ['replied_to', 'quoted', 'retweeted'],\n",
    "                            ['replied_to', 'retweeted']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can choose what (combination of) reaction types you wish to be included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_types = reaction_types_full_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quoted']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_to_opinion_changes(reaction_types):\n",
    "    \"\"\"Function to create the path to the opinion changes JSON file, based on the reaction types we took into consideration.\n",
    "\n",
    "    Args:\n",
    "        reaction_types (list): list of reaction types\n",
    "\n",
    "    Returns:\n",
    "        str: path to the opinion changes file\n",
    "    \"\"\"    \n",
    "    type = \"_\".join(reaction_types)\n",
    "    path = os.path.join(opinion_changes_path, f'{type}_OC.json')\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_reactions(merged_days, reaction_types):\n",
    "    \"\"\"Function to group reactions based on the reaction types list given as an input parameter, by the\n",
    "    'author_id' and 'reference_id' columns. This means that each group of reactions contains a (set of) reaction(s)\n",
    "    posted by the user identified by the 'author_id' and the source tweet identified by the 'reference_id'.\n",
    "\n",
    "    Args:\n",
    "        merged_days (pandas.core.frame.DataFrame): dataframe with all the data\n",
    "        reaction_types (list): list of reaction types we want to consider\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary where the key is a tuple of the form (author_id, reference_id)\n",
    "              and the value is a dataframe with all reactions corresponding to that combination\n",
    "    \"\"\"    \n",
    "    reactions = merged_days[merged_days['reference_type'].isin(reaction_types)]\n",
    "    multiple_reactions = reactions[reactions.duplicated(subset=['author_id', 'reference_id'], keep=False)]\n",
    "\n",
    "    # group the rows by the two columns\n",
    "    grouped_df = multiple_reactions.groupby(['author_id', 'reference_id'])\n",
    "    groups_of_reactions = grouped_df.groups\n",
    "\n",
    "    return groups_of_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_of_reactions = group_reactions(merged_days, reaction_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8692"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups_of_reactions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DICTIONARY FROM JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opinion_changes(path_to_opinion_changes):\n",
    "    \"\"\"Function that generates a dictionary based on a JSON file which contains the opinion changes within the reactions of the dataset.\n",
    "\n",
    "    Args:\n",
    "        path_to_opinion_changes (str): path to the JSON file associated with the opinion changes within the reactions\n",
    "                                               (e.g. /your/path/to/research-internship/files/opinion-changes-25_days/quoted_OC.json)\n",
    "\n",
    "    Returns:\n",
    "        dict: the original dictionary containing opinion changes from reactions\n",
    "    \"\"\"    \n",
    "    with open(path_to_opinion_changes) as f:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        opinion_changes_from_file = json.load(f)\n",
    "        # Create a new dictionary with tuple keys\n",
    "        original_opinion_changes = {}\n",
    "        for key in opinion_changes_from_file:\n",
    "            # Convert the string key to a tuple\n",
    "            new_key = eval(key)\n",
    "            # Add the key-value pair to the new dictionary\n",
    "            original_opinion_changes[new_key] = opinion_changes_from_file[key]\n",
    "            \n",
    "    return original_opinion_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_changes = load_opinion_changes(create_path_to_opinion_changes(reaction_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of opinion changes out of the interactions where one user reacted multiple times to a source tweet:\n",
      "13.1%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of opinion changes out of the interactions where one user reacted multiple times to a source tweet:\")\n",
    "print(f\"{round(len(opinion_changes) / len(groups_of_reactions) * 100, 1)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_opinion_change(opinion_changes):\n",
    "    \"\"\"Function that returns the group (pair of user id - source tweet id) which interacted more than once \n",
    "    in the context of a single source tweet, i.e. one user posted more than one reply to the same source tweet, \n",
    "    where the user who reacted had the most drastic opinion change,\n",
    "    based on the previously computed sentiments of the text.\n",
    "\n",
    "    Args:\n",
    "        opinion_changes (dict): dictionary with opinion changes\n",
    "\n",
    "    Returns:\n",
    "        tuple: pair of user id - source tweet id, where the biggest opinion change occured\n",
    "        str: type of change that occured, e.g. one user tends to agree with the source tweet after some time, \n",
    "             when initially he disagreed or vice-versa\n",
    "    \"\"\"    \n",
    "    change_type = 'negative'\n",
    "    biggest_change = 0\n",
    "    target_group = tuple()\n",
    "    for group, sentiments in opinion_changes.items():\n",
    "        change = max(biggest_change, max(sentiments) - min(sentiments))\n",
    "        if change > biggest_change:\n",
    "            biggest_change = change\n",
    "            target_group = group\n",
    "    \n",
    "    min_sentiment_index = opinion_changes[target_group].index(min(opinion_changes[target_group]))\n",
    "    max_sentiment_index = opinion_changes[target_group].index(max(opinion_changes[target_group]))\n",
    "    change_type = 'positive' if min_sentiment_index < max_sentiment_index else change_type\n",
    "\n",
    "    return target_group, change_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_group, change_type = biggest_opinion_change(opinion_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25098310, 1372044288083787776)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reactions_with_biggest_opinion_change(reactions, target_group):\n",
    "    \"\"\"Function that queries the reactions dataset and returns a list of the actual texts that the pair of users\n",
    "     (the author of the reaction and the author of the source tweet) posted.\n",
    "     The user id and source tweet id are passed on as input parameters (the target group).\n",
    "\n",
    "    Args:\n",
    "        replies (pandas Dataframe): the dataframe with the reactions\n",
    "        target_group (tuple): pair of user ids - source tweet id, whose posts had the biggest opinion change\n",
    "\n",
    "    Returns:\n",
    "        list: list of texts posted by the 2 users\n",
    "    \"\"\"    \n",
    "    condition1 = reactions['author_id'] == target_group[0]\n",
    "    condition2 = reactions['reference_id'] == target_group[1]\n",
    "\n",
    "    return reactions[condition1 & condition2].loc[:, 'text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_biggest_change = reactions_with_biggest_opinion_change(merged_days, target_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Very much so looking forward to outdoor music, Joe Biden length hugs, and staying home cause I want to, not cause I need to. https://t.co/7VuVM02mwq',\n",
       " 'Side effects: sore arm, and an overwhelming dread of having to go back to work tomorrow. https://t.co/7VuVM02mwq']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactions_biggest_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_opinion_change_type(opinion_changes, group):\n",
    "    \"\"\"Function to detect what type of opinion change occured in the case of a group (pair of user id - source tweet id) \n",
    "    which interacted.\n",
    "\n",
    "    Args:\n",
    "        opinion_changes (dict): dictionary with opinion changes\n",
    "        group (tuple): pair of user id - source tweet id that interacted through reactions \n",
    "                       and the respondent changed his/her viewpoint w.r.t. a source tweet\n",
    "\n",
    "    Returns:\n",
    "        str: either 'positive' (if the respondent now agrees after initially disagreeing) or 'negative'\n",
    "    \"\"\"    \n",
    "    min_sentiment_index = opinion_changes[group].index(min(opinion_changes[group]))\n",
    "    max_sentiment_index = opinion_changes[group].index(max(opinion_changes[group]))\n",
    "    \n",
    "    change_type = 'negative'\n",
    "    change_type = 'positive' if min_sentiment_index < max_sentiment_index else change_type\n",
    "\n",
    "    return change_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask indicating what type of opinion change each group has\n",
    "mask = {group: biggest_opinion_change_type(opinion_changes, group) for group in opinion_changes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_count_in_dict(dict, value_to_count):\n",
    "    \"\"\"Function to count the occurences of a certain value in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        dict (dict): dictionary where we need to count the occurences of a value\n",
    "        value_to_count (any): value to be counted\n",
    "\n",
    "    Returns:\n",
    "        int: number of occurences of value_to_count\n",
    "    \"\"\"    \n",
    "    # Create a reverse dictionary that maps values to their frequencies\n",
    "    reverse_dict = defaultdict(int)\n",
    "    for value in dict.values():\n",
    "        reverse_dict[value] += 1\n",
    "\n",
    "    # Count the occurrences of the specific value\n",
    "    count = reverse_dict.get(value_to_count, 0)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive opinion changes out of:\n",
      "- the interactions where one user reacted multiple times to a source tweet and an opinion change was detected => 50.7%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of positive opinion changes out of:\")\n",
    "print(f\"- the interactions where one user reacted multiple times to a source tweet and an opinion change was detected => {round(value_count_in_dict(mask, 'positive') / len(mask) * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of negative opinion changes out of:\n",
      "- the interactions where one user reacted multiple times to a source tweet and an opinion change was detected => 49.3%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of negative opinion changes out of:\")\n",
    "print(f\"- the interactions where one user reacted multiple times to a source tweet and an opinion change was detected => {round(value_count_in_dict(mask, 'negative') / len(mask) * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biggest_opinion_changes_deltas(path_to_opinion_changes):\n",
    "    opinion_changes = load_opinion_changes(path_to_opinion_changes)\n",
    "    deltas = { key: max(value) - min(value) for key, value in opinion_changes.items() }\n",
    "\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_labels = {\n",
    "    2: 'minimum',\n",
    "    3: 'slight',\n",
    "    4: 'considerable',\n",
    "    5: 'big',\n",
    "    6: 'very big',\n",
    "    7: 'huge',\n",
    "    8: 'maximum'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add value labels - adds the value of y\n",
    "def add_labels_y_value(x,y):\n",
    "    \"\"\"Function that takes the x and y-axis to be passed onto a plot function and generates labels,\n",
    "    such that on top of each y value, it is displayed centrally.\n",
    "\n",
    "    Args:\n",
    "        x (list): list of labels for x-axis of a plot\n",
    "        y (list): list of values for y-axis of a plot\n",
    "    \"\"\"    \n",
    "    for i in range(len(x)):\n",
    "        plt.text(x[i], y[i], y[i], ha = 'center', va = 'bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_deltas_OC(reaction_types, deltas_labels, root_path, number_of_days):\n",
    "    opinion_changes_deltas = compute_biggest_opinion_changes_deltas(create_path_to_opinion_changes(reaction_types))\n",
    "    # Get the values from the dictionary\n",
    "    deltas = list(opinion_changes_deltas.values())\n",
    "\n",
    "    # Use Counter to count the occurrences of each value\n",
    "    deltas_count = Counter(deltas)\n",
    "    percentages = { deltas_labels[pair[0]]: round(pair[1] / sum(deltas_count.values()) * 100, 1) \n",
    "               for pair in sorted(deltas_count.most_common(), key=lambda x: x[0])}\n",
    "    \n",
    "    keys = list(percentages.keys())\n",
    "    values = list(percentages.values())\n",
    "\n",
    "    # Create a bar chart of the counts\n",
    "    plt.bar(keys, values, edgecolor='black')\n",
    "    # Add labels to the top of each bar\n",
    "    add_labels_y_value(keys, values)\n",
    "    plt.xlabel('Biggest difference in opinion')\n",
    "    plt.ylabel('Percentage of groups')\n",
    "\n",
    "    long_title = f'Distribution of the intensity of the biggest opinion changes for { \", \".join(reaction_types) }'\n",
    "    # Wrap the title onto multiple lines\n",
    "    wrapped_title = textwrap.fill(long_title, width=50)\n",
    "    plt.title(wrapped_title, loc=\"center\", pad=10)\n",
    "\n",
    "    types = \"_\".join(reaction_types)\n",
    "    path = os.path.join(root_path, f'{types}_deltas_OC_{number_of_days}.png')\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_deltas_OC(reaction_types_full_list, deltas_labels, root_path, number_of_days):\n",
    "    for reaction_types in reaction_types_full_list:\n",
    "        plot_deltas_OC(reaction_types, deltas_labels, root_path, number_of_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_deltas_OC(reaction_types_full_list, deltas_labels, covaxxy_deltas_OC_graphs_path, number_of_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ADD VISUALIZATIONS FOR ALL INSIGHTS + IMPROVE PRINT MESSAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW COLUMN ADDITION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATION OF REPLIES_AND_QUOTES DATAFRAME, FOR WHICH WE WANT TO SEE IF THEY SUPPORT OR NOT THE SOURCE TWEET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replies_and_quotes(full_dataset):\n",
    "    condition_1 = full_dataset['reference_type'] == 'replied_to'\n",
    "    condition_2 = full_dataset['reference_type'] == 'quoted'\n",
    "\n",
    "    return full_dataset[condition_1 | condition_2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies_and_quotes = create_replies_and_quotes(merged_days)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTIONS TO ADD A NEW COLUMN TO THE test_replies_and_quotes DATAFRAME IN PARALLEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_replies_and_quotes = replies_and_quotes.head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "progress = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress():\n",
    "    global counter\n",
    "    global progress\n",
    "    global test_replies_and_quotes\n",
    "    ipython = get_ipython()\n",
    "    if ipython is not None:\n",
    "        counter = ipython.user_ns['counter']\n",
    "        progress = ipython.user_ns['progress']\n",
    "        test_replies_and_quotes = ipython.user_ns['test_replies_and_quotes']\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    if ((counter / len(test_replies_and_quotes)) >= progress):\n",
    "        print(f\"{counter} / {len(test_replies_and_quotes)} replies or quotes processed.\\n\")\n",
    "        progress += 0.001\n",
    "    if counter == len(test_replies_and_quotes):\n",
    "        print(\"New column inserted in the replies_and_quotes dataframe.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supports_source_tweet(text):\n",
    "    if not isinstance(text, str):\n",
    "        return '#'\n",
    "    \n",
    "    sentiment = senti.getSentiment(text, score='scale')[0]\n",
    "\n",
    "    # print_progress()\n",
    "    \n",
    "    return sentiment > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wrapper function that applies supports_source-tweet to a chunk of data\n",
    "def apply_function_to_chunk(chunk):\n",
    "    return chunk.apply(supports_source_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_support_source_tweet_column_parallel(replies_and_quotes):\n",
    "    # Split the DataFrame into chunks for parallel processing\n",
    "    num_chunks = multiprocessing.cpu_count()\n",
    "    chunks = np.array_split(replies_and_quotes['text'], num_chunks)\n",
    "\n",
    "    # Create a multiprocessing pool and apply the function to each chunk in parallel\n",
    "    with multiprocessing.Pool(processes=num_chunks) as pool:\n",
    "        results = pool.map(apply_function_to_chunk, chunks)\n",
    "\n",
    "    # Concatenate the results back into a single DataFrame\n",
    "    # replies_and_quotes['supports_source_tweet'] = pd.concat(results)\n",
    "    replies_and_quotes.insert(replies_and_quotes.columns.get_loc('text') + 1, 'supports_source_tweet', pd.concat(results))\n",
    "\n",
    "    return replies_and_quotes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARALLEL EXECUTION. Benchmark tests (my machine): 1000 recordings => 1m11.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_replies_and_quotes_parallel = add_support_source_tweet_column_parallel(test_replies_and_quotes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEQUENTIAL EXECUTION. Benchmark tests (my machine): 1000 recordings => 2m30.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_replies_and_quotes = replies_and_quotes.head(1000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_replies_and_quotes.insert(test_replies_and_quotes.columns.get_loc('text') + 1, 'supports_source_tweet', test_replies_and_quotes['text'].apply(supports_source_tweet))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK IF RESULTS ARE THE SAME FOR BOTH METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_replies_and_quotes_parallel.equals(test_replies_and_quotes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE TO MODIFY THE ORIGINAL DATAFRAME (WITH ALL REPLIES AND QUOTES), WITH AN ADDED COLUMN NAMED 'supports_source_tweet', USING PARALLEL COMPUTATION, AS WELL AS SAVE IT TO A .CSV FILE (UNCOMMENT CELLS TO RUN)\n",
    "\n",
    "NOTE: There are almost 1 million replies and quotes in the original dataframe, so the following statement is extremely time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replies_and_quotes = add_support_source_tweet_column_parallel(replies_and_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_replies_and_quotes = files_path + '/replies_and_quotes_modified.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the DataFrame to a CSV file\n",
    "# replies_and_quotes.to_csv(path_to_replies_and_quotes, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the distribution of the tweets per hour, I will parse the \"created_at\" column, extract the hour property and create a separate column in each dataframe. I will place it next to the \"created_at\" column in order to be easily verifiable. Data originates frmo the Twitter API, so it comes in a standard ISO 8601 format, which can be easily parsed using the parser module from the dateutil package.\n",
    "\n",
    "Note: the cell below runs for approximately 2m30' on my machine (~25-30 seconds for each file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, day in days.items():\n",
    "#     if 'hour' not in day.columns:\n",
    "#         day.insert(1, 'hour', day['created_at'].apply(lambda date: parser.parse(date).hour))\n",
    "#         print(f\"New 'hour' column inserted in the {key} dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, day in days.items():\n",
    "#     if 'hour' not in day.columns:\n",
    "#         hours = []\n",
    "#         for time in day.loc[:,\"created_at\"]:\n",
    "#             hour = parser.parse(time).hour\n",
    "#             hours.append(hour)\n",
    "#         day.insert(1, \"hour\", hours, True)\n",
    "#         print(key + \" - added 'hour' column\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final distribution is made up of the sum of all individual days' distributions. I save a figure in the graphs/ folder for each day, as well as an overall distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_distribution = pd.Series(0, index=days['1-3-2021'].loc[:,'hour'].sort_values(ascending=True).unique())\n",
    "# for key, day in days.items():\n",
    "#     hour_column_ascending = day.loc[:,\"hour\"].sort_values(ascending=True)\n",
    "#     distribution = hour_column_ascending.value_counts()[hour_column_ascending.unique()]\n",
    "#     final_distribution = final_distribution.add(distribution)\n",
    "#     axes = distribution.plot(kind='bar')\n",
    "#     figure_path = f\"{covaxxy_longitudinal_analysis_graphs}/{key}_distribution.png\"\n",
    "#     axes.figure.savefig(figure_path)\n",
    "#     plt.close()\n",
    "# axes = final_distribution.plot(kind='bar')\n",
    "# figure_path = f\"{covaxxy_longitudinal_analysis_graphs}/overall_distribution.png\"\n",
    "# axes.figure.savefig(figure_path)\n",
    "# plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "243101c165aceacaf115b49fc146265224cf91574f24df3021157e0d2dabdb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
