{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all variables in the current environment (if you have already run some cells) - clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the root folder of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_path = '/home/andreistoica12/research-internship'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with the path to the folder where we store the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/andreistoica12/research-internship/data/PhemeDataset'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 subfolders to store important files and graphs, respectively. If they already existed (from previous runnings of the project), delete the folders and their contents and create empty folders to store the current files and graphs, relevant to the current state of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = os.path.join(rootdir_path, 'files')\n",
    "if os.path.exists(files_path):\n",
    "   shutil.rmtree(files_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(files_path)\n",
    "\n",
    "graphs_path = os.path.join(rootdir_path, 'graphs')\n",
    "if os.path.exists(graphs_path):\n",
    "   shutil.rmtree(graphs_path, ignore_errors=False, onerror=None)\n",
    "os.makedirs(graphs_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I will analyse one story (a source tweet and the reactions to it) from the Charlie Hebdo shooting event. Hence, I save the path to the event folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "charlie_hebdo_event_path = data_path + \"/threads/en/charliehebdo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define a function that first reads the JSON file and stores it into a dictionary, then parses the date contained at the \"created_at\" key. The number returned is an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_hour(tweet_path):\n",
    "    with open(tweet_path) as f:\n",
    "        tweet = json.load(f)\n",
    "    date = parser.parse(tweet['created_at'])\n",
    "    return date.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define a function to return the source path, given the story path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_tweet_path(story_path):\n",
    "    source_dir_path = story_path + \"/source-tweets\"\n",
    "    source_path = source_dir_path + \"/\" + os.listdir(source_dir_path)[0]\n",
    "    \n",
    "    return source_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define a function to return a list of all reactions' paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reaction_tweets_paths(story_path):\n",
    "    reactions_paths_list = []\n",
    "    reactions_dir_path = story_path + \"/reactions\"\n",
    "    for reaction_name in os.listdir(reactions_dir_path):\n",
    "        reaction_path = reactions_dir_path + \"/\" + reaction_name\n",
    "        reactions_paths_list.append(reaction_path)\n",
    "        \n",
    "    return reactions_paths_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define a function to store all occurences of dates (only the hours) in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hours_list_story(story_path):\n",
    "    hours = []\n",
    "    source_path = source_tweet_path(story_path)\n",
    "    hour = tweet_hour(source_path)\n",
    "    hours.append(hour)\n",
    "    reactions_paths_list = reaction_tweets_paths(story_path)\n",
    "    for reaction_path in reactions_paths_list:\n",
    "        hour = tweet_hour(reaction_path)\n",
    "        hours.append(hour)\n",
    "    \n",
    "    return hours"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define a function to return a pandas Series, representing the distribution of the hours of tweets posted regarding a specific event given as an input parameter. I chose to convert the list to a pandas Series due to the ease in creating a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_distribution_event(event_path):\n",
    "    hours = []\n",
    "    for story_id in os.listdir(event_path):\n",
    "        story_path = event_path + \"/\" + story_id\n",
    "        hours.extend(hours_list_story(story_path))\n",
    "    hours.sort()\n",
    "    hours_series = pd.Series(hours)\n",
    "    distribution = hours_series.value_counts()[hours_series.unique()]\n",
    "    \n",
    "    return distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is delegated to plot the distribution per hour of the tweets sent about a specific topic/event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_distribution(event_name, distribution):\n",
    "    axes = distribution.plot(kind='bar')\n",
    "    figure_path = \"{graphs_path}/{event}_distribution.png\".format(graphs_path = graphs_path, event = event_name)\n",
    "    axes.figure.savefig(figure_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = time_distribution_event(charlie_hebdo_event_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_event_distribution(\"charlie_hebdo\", distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "243101c165aceacaf115b49fc146265224cf91574f24df3021157e0d2dabdb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
